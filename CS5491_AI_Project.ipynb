{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsjEr23wKHN2"
   },
   "source": [
    "# Project for CS5491 Artificial Intelligence\n",
    "### NETWORK STRUCTURE OPTIMIZATION FOR YOLOV8 ALGORITHM\n",
    "\n",
    "LAN JINGSEN 58158499\n",
    "\n",
    "WANG GAOYU 58285673\n",
    "\n",
    "This code is part of the project, we will based on the official yolov8 code, making links to https://github.com/ultralytics/ultralytics, we will improve on this code, finish our experiment. The following is a tutorial on replicating the experimental results, including defining deformable convolution, calling CBAM, adjusting the network structure of yolov8, and how to start training. This tutorial is to reflect how we implemented this project at the code level. Due to the computational power of colab, This tutorial will not complete the entire process of running training yolov8, and the specific experimental results will be reflected in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrcSQm81MvgB"
   },
   "source": [
    "First we need to clone the code from the official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIXNgCAmJkrT",
    "outputId": "ac756b37-215b-4af4-8f68-b926a7d2f6a5"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/ultralytics.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ox3bhmTNBmb"
   },
   "source": [
    "Now we need to install the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3U8n_QqNAoK",
    "outputId": "0b54b3fd-575a-4505-a08f-41212722fe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66-LfVONN_cr"
   },
   "source": [
    "Firstly, since the official code does not define the deformable convolution, we need to define the deformable convolution class in the \"/content/ultralytics/ultralytics/nn/modules/block.py\" file so that we can call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "D613YsYHN-VW",
    "outputId": "2659925f-aa20-4c76-ff43-0f11b888950d"
   },
   "outputs": [],
   "source": [
    "from torchvision.ops import DeformConv2d\n",
    "class DeformableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DeformableConv, self).__init__()\n",
    "        # Offset convolution layer to generate offsets for deformable convolution\n",
    "        self.offset_conv = nn.Conv2d(in_channels, 2 * kernel_size * kernel_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        # Mask convolution layer to generate masks for deformable convolution\n",
    "        self.mask_conv = nn.Conv2d(in_channels, kernel_size * kernel_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        # Deformable convolution layer\n",
    "        self.conv = DeformConv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generate offsets and masks\n",
    "        offset = self.offset_conv(x)\n",
    "        mask = self.mask_conv(x)\n",
    "        # Normalize offsets to range [-1, 1]\n",
    "        offset = 2 * torch.sigmoid(offset) - 1\n",
    "        mask = torch.sigmoid(mask)\n",
    "        # Perform deformable convolution\n",
    "        out = self.conv(x, offset)\n",
    "        # Element-wise multiplication with the mask\n",
    "        out = out * mask\n",
    "        return out\n",
    "\n",
    "class C2f_DCN(nn.Module):\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):\n",
    "        super(C2f_DCN, self).__init__()\n",
    "        # Calculate the number of hidden channels\n",
    "        self.c = int(c2 * e)\n",
    "        # First deformable convolution layer\n",
    "        self.cv1 = DeformableConv(c1, 2 * self.c, kernel_size=1)\n",
    "        # Second deformable convolution layer\n",
    "        self.cv2 = DeformableConv((2 + n) * self.c, c2, kernel_size=1)\n",
    "        # List of bottleneck modules\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the first deformable convolution layer\n",
    "        y = list(self.cv1(x).chunk(2, 1))\n",
    "        # Pass the output of the first layer through the bottleneck modules\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        # Pass the concatenated output through the second deformable convolution layer\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "\n",
    "    def forward_split(self, x):\n",
    "        # Pass input through the first deformable convolution layer\n",
    "        y = list(self.cv1(x).split((self.c, self.c), 1))\n",
    "        # Pass the output of the first layer through the bottleneck modules\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        # Pass the concatenated output through the second deformable convolution layer\n",
    "        return self.cv2(torch.cat(y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1cv7NTiQXlu"
   },
   "source": [
    "After defining C2f_DCN, we need to add it to the “all” variable in this file. The complete “all\" variable should look like the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3YTKO6qPRWn"
   },
   "outputs": [],
   "source": [
    "__all__ = (\n",
    "    \"DFL\",\n",
    "    \"HGBlock\",\n",
    "    \"HGStem\",\n",
    "    \"SPP\",\n",
    "    \"SPPF\",\n",
    "    \"C1\",\n",
    "    \"C2\",\n",
    "    \"C3\",\n",
    "    \"C2f\",\n",
    "    \"C2f_DCN\", # here !!!!!!\n",
    "    \"C2fAttn\",\n",
    "    \"ImagePoolingAttn\",\n",
    "    \"ContrastiveHead\",\n",
    "    \"BNContrastiveHead\",\n",
    "    \"C3x\",\n",
    "    \"C3TR\",\n",
    "    \"C3Ghost\",\n",
    "    \"GhostBottleneck\",\n",
    "    \"Bottleneck\",\n",
    "    \"BottleneckCSP\",\n",
    "    \"Proto\",\n",
    "    \"RepC3\",\n",
    "    \"ResNetLayer\",\n",
    "    \"RepNCSPELAN4\",\n",
    "    \"ADown\",\n",
    "    \"SPPELAN\",\n",
    "    \"CBFuse\",\n",
    "    \"CBLinear\",\n",
    "    \"Silence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35sWlj2ySybC"
   },
   "source": [
    "/content/ultralytics/ultralytics/nn/modules/init.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "san54sEwRo4h"
   },
   "outputs": [],
   "source": [
    "from .block import (\n",
    "    C1,\n",
    "    C2,\n",
    "    C3,\n",
    "    C3TR,\n",
    "    DFL,\n",
    "    SPP,\n",
    "    SPPELAN,\n",
    "    SPPF,\n",
    "    ADown,\n",
    "    BNContrastiveHead,\n",
    "    Bottleneck,\n",
    "    BottleneckCSP,\n",
    "    C2f,\n",
    "    C2f_DCN, # here !!!!!!\n",
    "    ......\n",
    ")\n",
    "__all__ = (\n",
    "    \"Conv\",\n",
    "    \"Conv2\",\n",
    "    \"LightConv\",\n",
    "    \"RepConv\",\n",
    "    \"DWConv\",\n",
    "    \"DWConvTranspose2d\",\n",
    "    \"ConvTranspose\",\n",
    "    \"Focus\",\n",
    "    \"GhostConv\",\n",
    "    \"ChannelAttention\",\n",
    "    \"SpatialAttention\",\n",
    "    \"CBAM\",\n",
    "    \"Concat\",\n",
    "    \"TransformerLayer\",\n",
    "    \"TransformerBlock\",\n",
    "    \"MLPBlock\",\n",
    "    \"LayerNorm2d\",\n",
    "    \"DFL\",\n",
    "    \"HGBlock\",\n",
    "    \"HGStem\",\n",
    "    \"SPP\",\n",
    "    \"SPPF\",\n",
    "    \"C1\",\n",
    "    \"C2\",\n",
    "    \"C3\",\n",
    "    \"C2f\",\n",
    "    \"C2f_DCN\", # here !!!!!!\n",
    "    ......\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51AvdnfeSx3R"
   },
   "source": [
    "/content/ultralytics/ultralytics/nn/tasks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3mzcDT6TNFL"
   },
   "outputs": [],
   "source": [
    "from ultralytics.nn.modules import (\n",
    "    AIFI,\n",
    "    C1,\n",
    "    C2,\n",
    "    C3,\n",
    "    C3TR,\n",
    "    OBB,\n",
    "    SPP,\n",
    "    SPPELAN,\n",
    "    SPPF,\n",
    "    ADown,\n",
    "    Bottleneck,\n",
    "    BottleneckCSP,\n",
    "    C2f,\n",
    "    C2f_DCN, # here !!!\n",
    "    C2fAttn,\n",
    "    .....\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-PILXVqUxOX"
   },
   "source": [
    "Now, we also need to define CBAM. Unlike before, in the official code, CBAM is already defined as a class in \"/content/ultralytics/ultralytics/nn/modules/conv.py\", but it is not being called. Therefore, we need to repeat the previous steps to include CBAM in the components that can be called during model generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv7HcFeSU0Cp"
   },
   "source": [
    "/content/ultralytics/ultralytics/nn/tasks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA2zXDAhU09e"
   },
   "outputs": [],
   "source": [
    "from ultralytics.nn.modules import (\n",
    "    AIFI,\n",
    "    CBAM, #here\n",
    "    C1,\n",
    "    C2,\n",
    "    C3,\n",
    "    C3TR,\n",
    "    OBB,\n",
    "    SPP,\n",
    "    ........\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-ORgGDJWGLa"
   },
   "source": [
    "Now we need to create a YAML file to define our improved YOLOv8 architecture. I will place it here: /content/ultralytics/ultralytics/cfg/models/v8/yolov8s-dcn-cbam.yaml. As designed in the report, the file content is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkNifj2MVPlL"
   },
   "outputs": [],
   "source": [
    "# Ultralytics YOLO 🚀, AGPL-3.0 license\n",
    "# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\n",
    "\n",
    "# Parameters\n",
    "nc: 80 # number of classes\n",
    "scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n",
    "  # [depth, width, max_channels]\n",
    "  s: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs\n",
    "\n",
    "\n",
    "# YOLOv8.0n backbone\n",
    "backbone:\n",
    "  # [from, repeats, module, args]\n",
    "  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n",
    "  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n",
    "  - [-1, 3, C2f, [128, True]]\n",
    "  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n",
    "  - [-1, 6, C2f_DCN, [128,128,1, True]]\n",
    "  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n",
    "  - [-1, 6, C2f_DCN, [256, 256,1,True]]\n",
    "  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n",
    "  - [-1, 3, C2f, [1024, True]]\n",
    "  - [-1, 1, SPPF, [1024, 5]] # 9\n",
    "\n",
    "# YOLOv8.0n head\n",
    "head:\n",
    "  - [-1,1,CBAM,[512]]\n",
    "  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n",
    "  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n",
    "  - [-1, 3, C2f, [512]] # 12\n",
    "\n",
    "  - [-1,1,CBAM,[256]]\n",
    "  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n",
    "  - [[-1, 4], 1, Concat, [1]] # cat backbone P3\n",
    "  - [-1, 3, C2f, [256]] # 15 (P3/8-small)\n",
    "\n",
    "  - [-1,1,CBAM,[128]]\n",
    "  - [-1, 1, Conv, [256, 3, 2]]\n",
    "  - [[-1, 12], 1, Concat, [1]] # cat head P4\n",
    "  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)\n",
    "\n",
    "  - [-1,1,CBAM,[256]]\n",
    "  - [-1, 1, Conv, [512, 3, 2]]\n",
    "  - [[-1, 9], 1, Concat, [1]] # cat head P5\n",
    "  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)\n",
    "\n",
    "  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLx_r5cgWgXW"
   },
   "source": [
    "Now we can write a training script to start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    " \n",
    "model = YOLO(model=\"yolov8s-dcn-cbam.yaml\")\n",
    "\n",
    "\n",
    " \n",
    "data = \"ultralytics/cfg/datasets/VOC.yaml\"\n",
    " \n",
    "model.train(data=data, epochs=100, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWzNaj1-W36A",
    "outputId": "e56119fd-46fe-48b4-abe9-63ae6e130de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.0 🚀 Python-3.9.19 torch-2.2.2 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s-dcn-cbam.yaml, data=ultralytics/cfg/datasets/VOC.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/senniko/Desktop/ultralytics/runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    232332  ultralytics.nn.modules.block.C2f_DCN         [128, 128, 1, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    923404  ultralytics.nn.modules.block.C2f_DCN         [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    262754  ultralytics.nn.modules.conv.CBAM             [512]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1     65890  ultralytics.nn.modules.conv.CBAM             [256]                         \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 18                  -1  1     16610  ultralytics.nn.modules.conv.CBAM             [128]                         \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    624128  ultralytics.nn.modules.block.C2f             [896, 256, 1]                 \n",
      " 22                  -1  1     65890  ultralytics.nn.modules.conv.CBAM             [256]                         \n",
      " 23                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 24             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 25                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 26        [15, 18, 21]  1   3755020  ultralytics.nn.modules.head.Detect           [20, [256, 128, 256]]         \n",
      "YOLOv8s-dcn-cbam summary: 283 layers, 13486412 parameters, 13486396 gradients, 54.9 GFLOPs\n",
      "\n",
      "Freezing layer 'model.26.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/senniko/Desktop/datasets/datasets/VOC/labels/train2007.ca\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/senniko/Desktop/datasets/datasets/VOC/labels/test2007.cache\u001b[0m\n",
      "Plotting labels to /Users/senniko/Desktop/ultralytics/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 53 weight(decay=0.0), 92 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/senniko/Desktop/ultralytics/runs/detect/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/1035 [00:00<?, ?it/s]^C\n",
      "  0%|          | 0/1035 [00:11<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/train.py\", line 9, in <module>\n",
      "    model.train(data=data, epochs=100, batch=16)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/engine/model.py\", line 673, in train\n",
      "    self.trainer.train()\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/engine/trainer.py\", line 198, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/engine/trainer.py\", line 370, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "  File \"/Users/senniko/anaconda3/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/senniko/anaconda3/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/nn/tasks.py\", line 90, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/nn/tasks.py\", line 269, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/utils/loss.py\", line 222, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "  File \"/Users/senniko/anaconda3/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/senniko/anaconda3/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/senniko/anaconda3/envs/AI/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/utils/tal.py\", line 79, in forward\n",
      "    target_labels, target_bboxes, target_scores = self.get_targets(gt_labels, gt_bboxes, target_gt_idx, fg_mask)\n",
      "  File \"/Users/senniko/Desktop/AI/ultralytics/ultralytics/utils/tal.py\", line 207, in get_targets\n",
      "    fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  # (b, h*w, 80)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python /Users/senniko/Desktop/AI/ultralytics/train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is already training properly, and the printed model architecture is exactly what we wanted. Due to the long training time, we are interrupting the training process here. The specific experimental results can be viewed in the report."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
